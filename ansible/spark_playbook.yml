---
- hosts: all
  vars:
    lkspark_git_url: "https://github.com/lkhq/laniakea-spark.git"
    firehose_git_url: "https://github.com/fedora-static-analysis/firehose.git"
  become: yes
  tasks:
    - apt: update_cache=yes upgrade=dist
    - apt: name=git
    - apt: name=dput-ng
    - apt: name=devscripts install_recommends=no
    - apt: name=python3-setuptools
    - apt: name=python3-debian
    - apt: name=python3-zmq
    - apt: name=python3-tomlkit

    - name: Ensure lkspark user
      shell: adduser --force-badname --system --home /var/lib/lkspark/ --no-create-home --quiet _lkspark || true
    - name: Ensure directory permissions
      shell: chown _lkspark:nogroup /var/lib/lkspark || true

    - name: Create buildd directory
      file:
        path: /srv/buildd
        state: directory
        owner: _lkspark
        group: nogroup

    # set up Firehose Git repository
    - stat: path=/srv/buildd/firehose-git
      register: firehose_git

    - shell: git fetch && git reset --hard origin/master
      args:
        chdir: /srv/buildd/firehose-git
      when: firehose_git.stat.exists == True

    - shell: git clone {{ firehose_git_url }} firehose-git
      args:
        chdir: /srv/buildd/
      when: firehose_git.stat.exists == False

    - shell: python3 setup.py build && python3 setup.py install
      args:
        chdir: /srv/buildd/firehose-git

    # set up Laniakea Spark Git repository
    - stat: path=/srv/buildd/spark-git
      register: spark_git

    - shell: git fetch && git reset --hard origin/master
      args:
        chdir: /srv/buildd/spark-git
      when: spark_git.stat.exists == True

    - shell: git clone {{ lkspark_git_url }} spark-git
      args:
        chdir: /srv/buildd/
      when: spark_git.stat.exists == False

    - shell: python3 setup.py build && python3 setup.py install
      args:
        chdir: /srv/buildd/spark-git

    - name: Installing spark system files
      shell: python3 install-sysdata.py --prefix=/usr/local/
      args:
        chdir: /srv/buildd/spark-git

    - systemd:
        daemon_reload: yes

    - shell: hostname
      register: hostname

    - file: path=/var/lib/lkspark/ state=directory owner=_lkspark group=nogroup

    - file: state=directory path=/etc/laniakea/keys/curve/secret/

    - template: dest=/etc/laniakea/keys/curve/{{ hostname.stdout }}_lighthouse-server.pub src=keys/lighthouse-server.pub owner=_lkspark group=nogroup mode=0600

    - template: dest=/etc/laniakea/keys/curve/secret/{{ hostname.stdout }}-spark_private.sec src=keys/{{ hostname.stdout }}-spark_private.sec group=nogroup owner=_lkspark mode=0600

    - template: dest=/srv/buildd/{{ hostname.stdout }}_secret.gpg src=keys/{{ hostname.stdout }}_secret.gpg group=nogroup owner=_lkspark mode=0600

    - shell: sudo -H -u lkspark gpg --allow-secret-key-import --import /srv/buildd/{{ hostname.stdout }}_secret.gpg && touch /var/lib/lkspark/.ansible-pgp-imported
      args:
        creates: /var/lib/lkspark/.ansible-pgp-imported

    - name: Get the builder PGP fingerprint
      shell: 'sudo -H -u lkspark gpg --fingerprint --with-colons ''*@{{ worker_email_domain }}'' | grep "^fpr" | cut -d: -f10'
      register: gpg_fingerprint_cmd

    - template: dest=/etc/laniakea/spark.toml src=spark/spark.toml.j2
      vars:
        machine_owner: "{{ machine_owner }}"
        gpg_fingerprint: "{{ gpg_fingerprint_cmd.stdout }}"
        lighthouse_server: "{{ lighthouse_server }}"
        accepted_job_types: "{{ host_accepted_jobs[hostname.stdout] }}"

    - template: dest=/etc/dput.d/metas/{{ dput_profile }}.json src=dput/{{ dput_profile }}_meta.json

    - template: dest=/etc/dput.d/profiles/{{ dput_profile }}.json src=dput/{{ dput_profile }}_profile.json

    - name: Enable and start Laniakea Spark daemon
      systemd:
        state: restarted
        daemon_reload: yes
        enabled: yes
        name: laniakea-spark
